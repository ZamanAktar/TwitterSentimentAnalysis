{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e74427",
   "metadata": {},
   "source": [
    "## To replicate the sentiment analysis with data from twitter:\n",
    "### A. Start a notebook instance in machine Learning Lab \n",
    "### B. Open the example link and download the source code from Github repository.\n",
    "### C. Copy, paste and modify the python code file in the notebook"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad9799ca",
   "metadata": {},
   "source": [
    "# Step 1: Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Libraries\n",
    "!pip install textblob\n",
    "!pip install tweepy\n",
    "!pip install pycountry\n",
    "!pip install wordcloud\n",
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb58431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5739ffa",
   "metadata": {},
   "source": [
    "# Step 2: Authentication for Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "consumerKey = \"2CJbp8m7Rg26LtZEKAeVXWceG\"\n",
    "consumerSecret = \"IbULWKlS0uvhLnMTcFkzvMjDfZUcBM6eVbdLYMUbNafhieX8Y6\"\n",
    "accessToken = \"1119095264961126402-8QDK0FvTjGmV7w1hUtGsTyCyH77bNE\"\n",
    "accessTokenSecret = \"unheMaBnZsHrcBt3mK1bE8Ib4wtE3tPtAwSA65Y0zWIK0\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cef439",
   "metadata": {},
   "source": [
    "# Step 3: Getting Tweets With Keyword or Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole) \n",
    "\n",
    "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "noOfTweet = int(input (\"Please enter how many tweets to analyze: \"))\n",
    "\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "positive  = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "\n",
    "\n",
    "for tweet in tweets:\n",
    "    \n",
    "    #print(tweet.text)\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    \n",
    "    if neg > pos:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "\n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    "    \n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1\n",
    "\n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "print(\"positive number: \",len(positive_list))\n",
    "print(\"negative number: \", len(negative_list))\n",
    "print(\"neutral number: \",len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating PieCart\n",
    "\n",
    "labels = ['Positive ['+str(positive)+'%]' , 'Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['yellowgreen', 'blue','red']\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(labels)\n",
    "plt.title(\"Sentiment Analysis Result for keyword=  \"+keyword+\"\" )\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacea8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7fa68",
   "metadata": {},
   "source": [
    "# Extracting text values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "tw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ccd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text (RT, Punctuation etc)\n",
    "\n",
    "#Creating new dataframe and new features\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "\n",
    "#Removing RT, Punctuation etc\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
    "rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
    "tw_list[\"text\"] = tw_list.text.str.lower()\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Negative, Positive, Neutral and Compound values\n",
    "\n",
    "tw_list[['polarity', 'subjectivity']] = tw_list['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in tw_list['text'].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    if neg > pos:\n",
    "        tw_list.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif pos > neg:\n",
    "        tw_list.loc[index, 'sentiment'] = \"positive\"\n",
    "    else:\n",
    "        tw_list.loc[index, 'sentiment'] = \"neutral\"\n",
    "    tw_list.loc[index, 'neg'] = neg\n",
    "    tw_list.loc[index, 'neu'] = neu\n",
    "    tw_list.loc[index, 'pos'] = pos\n",
    "    tw_list.loc[index, 'compound'] = comp\n",
    "\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db37581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "\n",
    "tw_list_negative = tw_list[tw_list[\"sentiment\"]==\"negative\"]\n",
    "tw_list_positive = tw_list[tw_list[\"sentiment\"]==\"positive\"]\n",
    "tw_list_neutral = tw_list[tw_list[\"sentiment\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec543cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for count_values_in single columns\n",
    "\n",
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de198674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count_values for sentiment\n",
    "count_values_in_column(tw_list,\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for Pie Chart\n",
    "pc = count_values_in_column(tw_list,\"sentiment\")\n",
    "names= pc.index\n",
    "size=pc[\"Percentage\"]\n",
    " \n",
    "# Create a circle for the center of the plot\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(size, labels=names, colors=['green','blue','red'])\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46881af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Create Wordcloud\n",
    "\n",
    "def create_wordcloud(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wc = WordCloud(background_color=\"white\", width=600, height=400,               \n",
    "                  max_words=300,\n",
    "                  stopwords=stopwords,\n",
    "                  repeat=True)\n",
    "    wc.generate(str(text))\n",
    "    \n",
    "    plt.imshow(wc)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29918858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for all tweets\n",
    "create_wordcloud(tw_list[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f33cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for positive sentiment\n",
    "create_wordcloud(tw_list_positive[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for negative sentiment\n",
    "create_wordcloud(tw_list_negative[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for neutral sentiment\n",
    "create_wordcloud(tw_list_neutral[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d231c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
